{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "dataset = pd.read_csv('MARAll.csv')\n",
    "X = dataset.iloc[:, 4:10].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PolynomialFeatures'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-6568f9663a78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# polynomial regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteraction_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'PolynomialFeatures'"
     ]
    }
   ],
   "source": [
    "# polynomial regression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomial_features = PolynomialFeatures(degree=degrees[i],include_bias=False)\n",
    "linear_regression = LinearRegression()\n",
    "pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "# sklearn.preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.23018615e-01   3.64649095e-01   2.07026714e-01  -2.67708730e-01\n",
      "  -8.23255597e-01  -2.65971946e-02  -1.37729005e+00  -4.75107752e-01\n",
      "  -2.09616223e+00   4.59841850e-01  -3.14949629e-02   5.30154397e-01\n",
      "  -2.34758079e-01   2.81507827e-01   2.82681657e-01  -7.16780140e-01\n",
      "  -3.33347048e-01  -3.13933707e-02   2.72887863e-01   8.54097940e-02\n",
      "   1.80844477e-01  -3.11955562e-01  -3.64823741e-02  -2.37113276e-01\n",
      "   1.60474983e-01  -4.25355904e-01   3.40619558e-01   8.29952512e-01\n",
      "   3.93906575e-01   2.77512410e-01  -1.05088433e+00  -2.81369676e-01\n",
      "   7.00755834e-01  -1.82044504e-01   3.91274578e-01   1.86379654e-01\n",
      "  -5.78733074e-01   3.94190924e-01   5.76830093e-01   8.22101975e-01\n",
      "   2.84233797e-01  -4.11786671e-01  -3.42044383e-01   6.88501979e-01\n",
      "  -7.46599517e-01  -5.14198149e-01   8.11232208e-01   1.95809986e-01\n",
      "  -4.70837822e-01  -1.05351356e+00  -6.93952797e-02  -4.69185101e-01\n",
      "  -4.08382112e-01  -4.30175097e-01  -3.95974566e-01  -4.04491220e-01\n",
      "  -3.10288487e-01  -3.87112725e-01  -1.27094351e-01  -3.95974566e-01\n",
      "   9.99565731e-01   8.57794241e-01   5.74325422e-01  -7.94999217e-01\n",
      "   1.62584720e-01   1.52771272e-01  -9.88544150e-02   5.73977264e-01\n",
      "  -1.98940332e-02   3.60205829e-01   5.24696846e-02   5.95041109e-01\n",
      "  -1.22998121e+00  -3.80992861e-01   7.01522056e-01  -3.87112725e-01\n",
      "   8.21506428e-01  -6.95772080e-01  -2.51219106e-01  -4.30175097e-01\n",
      "   1.05882082e-01  -4.15393105e-01   3.54125992e-01   2.24430441e-01\n",
      "   1.75984432e-01   4.86146307e-01  -1.23916340e+00   5.10933064e-02\n",
      "   7.02122585e-02   4.46017401e-01   7.12534573e-01  -5.23791931e-02\n",
      "  -3.94823740e-02   7.64398282e-01   3.88480288e-01  -1.11662100e+00\n",
      "  -7.11000464e-01  -9.16031060e-01  -3.78647340e-01   1.41529443e+00\n",
      "   1.96221441e-01  -3.78328679e-01   6.08947094e-01   7.15655810e-01\n",
      "   3.63123203e-01  -7.89856190e-01  -3.15181395e-01   2.60582219e-01\n",
      "   5.37197302e-01   2.86567757e-01   3.10445261e-01   9.34946879e-04\n",
      "   5.99872468e-01   9.81318189e-01   1.20674091e-01  -1.22998121e+00\n",
      "   9.39103957e-01   1.51528952e+00  -2.36629108e-01  -8.69529151e-02\n",
      "  -2.97746685e-01  -4.90119661e-02  -1.27094351e-01   8.23856676e-01\n",
      "  -5.80995049e-02   1.23614641e-01   8.57107469e-01   4.45965582e-01\n",
      "  -3.33347048e-01  -2.79817607e-01  -4.83918260e-01   2.54380536e-01\n",
      "   4.68780466e-01  -8.78646159e-01   2.19075821e-01   7.52052895e-01\n",
      "   2.57470820e-02   3.42589910e-01   1.15049153e+00  -1.82044504e-01\n",
      "  -2.49959553e-01  -5.03981130e-01  -6.67698135e-01   7.61275799e-01\n",
      "  -3.15678771e-01  -1.47992298e-01  -6.17037132e-01  -9.59376878e-01\n",
      "  -3.15595619e-01   8.69411198e-01  -1.18019262e-01  -2.45319932e-01\n",
      "  -2.64255821e-02  -8.23669821e-01   6.68631551e-01  -1.15940732e-01\n",
      "   6.32646594e-01  -1.51280144e+00  -6.64823563e-01   1.96954271e-01\n",
      "  -6.64823563e-01  -7.56205158e-01   6.38517064e-01  -8.35882494e-01\n",
      "   3.94602379e-01   5.99757066e-01  -9.65438106e-02  -3.42176856e-01\n",
      "  -3.26133205e-01   7.04974326e-02   4.86914017e-01   9.19746579e-01\n",
      "   1.07541824e-01  -3.75821107e-01   5.36482037e-01  -3.46966087e-01\n",
      "   1.01555782e-01  -7.79489123e-01  -4.34983213e-01   9.39103957e-01\n",
      "   6.34996842e-01   5.04367185e-01  -6.39112555e-01  -2.10303184e-01\n",
      "  -4.84050733e-01  -1.02126301e-01  -6.98122328e-01   1.09404204e+00\n",
      "  -2.21132547e-01   1.01553014e-01  -7.88891267e-01   1.20802552e+00\n",
      "   8.54338809e-01  -6.60157502e-01   1.15121018e+00  -7.96636691e-01\n",
      "  -1.50780365e+00  -8.87204205e-01   1.02428938e-01   8.24729131e-01\n",
      "  -5.10413306e-01   1.03391093e-01  -7.20894860e-02   2.26078294e-01\n",
      "   9.99565731e-01  -7.25274139e-02  -7.17527916e-02  -6.86164110e-01\n",
      "   9.81815967e-01   2.09492230e-01  -8.55652527e-01  -5.80866908e-01\n",
      "   5.57475460e-01   8.53298090e-01  -9.60297517e-02   2.89196987e-01\n",
      "  -3.50033925e-02   6.82018793e-01  -1.72222038e-01  -4.39072502e-01\n",
      "  -2.11486508e-01   1.19555565e-02   4.86914017e-01  -5.78237678e-01\n",
      "   5.84812572e-01  -9.93041576e-01   5.18340712e-01  -5.13235994e-01\n",
      "  -1.03195730e+00   2.41864391e-01  -2.27267073e-01  -6.97189323e-01\n",
      "   1.36219913e-02   2.77548354e-01  -6.59404801e-01   1.85772750e-01\n",
      "   1.48565657e+00  -8.01856624e-01  -3.16090226e-01   2.60861201e-01\n",
      "   2.56594092e-01  -7.47159704e-03   3.03615225e-01  -5.62541297e-01\n",
      "  -5.39717210e-01  -8.78646159e-01   9.19335123e-01   1.74548714e-01\n",
      "  -4.08793568e-01  -6.54033255e-03   3.25926418e-01   8.69217775e-01\n",
      "  -1.73543925e-01   3.60413035e-02  -2.51630561e-01   1.35537942e+00\n",
      "  -9.23424540e-01  -1.30248058e-01  -8.54912155e-02  -3.44527286e-02\n",
      "   2.76586199e-01   3.04298398e-01  -9.60764971e-01   5.06206010e-01\n",
      "  -8.83116912e-01   1.75984432e-01  -9.25091615e-01   5.03976317e-02\n",
      "   9.00645439e-01  -2.73907620e-02]\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)\n",
    "y_train_pred = regr.predict (X_train)\n",
    "# print(y_train_pred)\n",
    "# print(y_train-abs(y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Interception: \\n', regr.intercept_)\n",
    "r2_score(y_train, y_pred, sample_weight=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 0.41145527  0.27898175  1.66707486 -0.96215495  0.7527012   0.00276802]\n",
      "Mean squared error: 0.24\n",
      "Variance score: 0.87\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting multiple lineaar regression to the training set\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import cross_validation\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "n_Sample = len(X_train) # Number of training samples\n",
    "degrees = [1, 4, 15] # Degree of Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269] [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134] [135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152\n",
      " 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206\n",
      " 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242\n",
      " 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260\n",
      " 261 262 263 264 265 266 267 268 269]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=2)\n",
    "for X_train, X_validation in kf.split(X_train):\n",
    "    print(\"%s %s\" % (X_train, X_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.35</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 21 Feb 2018</td> <th>  Prob (F-statistic):</th> <td>2.22e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:08:33</td>     <th>  Log-Likelihood:    </th> <td> -705.99</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>   1424.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   294</td>      <th>  BIC:               </th> <td>   1446.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.4000</td> <td>    0.078</td> <td>    5.123</td> <td> 0.000</td> <td>    0.246</td> <td>    0.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.2850</td> <td>    0.109</td> <td>    2.613</td> <td> 0.009</td> <td>    0.070</td> <td>    0.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    1.6771</td> <td>    0.271</td> <td>    6.182</td> <td> 0.000</td> <td>    1.143</td> <td>    2.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>   -0.9964</td> <td>    0.379</td> <td>   -2.627</td> <td> 0.009</td> <td>   -1.743</td> <td>   -0.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.8506</td> <td>    0.609</td> <td>    1.397</td> <td> 0.163</td> <td>   -0.348</td> <td>    2.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>   -0.1535</td> <td>    1.068</td> <td>   -0.144</td> <td> 0.886</td> <td>   -2.256</td> <td>    1.949</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>16.381</td> <th>  Durbin-Watson:     </th> <td>   0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  29.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.314</td> <th>  Prob(JB):          </th> <td>4.56e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.393</td> <th>  Cond. No.          </th> <td>    13.7</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.214\n",
       "Model:                            OLS   Adj. R-squared:                  0.198\n",
       "Method:                 Least Squares   F-statistic:                     13.35\n",
       "Date:                Wed, 21 Feb 2018   Prob (F-statistic):           2.22e-13\n",
       "Time:                        17:08:33   Log-Likelihood:                -705.99\n",
       "No. Observations:                 300   AIC:                             1424.\n",
       "Df Residuals:                     294   BIC:                             1446.\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.4000      0.078      5.123      0.000       0.246       0.554\n",
       "x2             0.2850      0.109      2.613      0.009       0.070       0.500\n",
       "x3             1.6771      0.271      6.182      0.000       1.143       2.211\n",
       "x4            -0.9964      0.379     -2.627      0.009      -1.743      -0.250\n",
       "x5             0.8506      0.609      1.397      0.163      -0.348       2.049\n",
       "x6            -0.1535      1.068     -0.144      0.886      -2.256       1.949\n",
       "==============================================================================\n",
       "Omnibus:                       16.381   Durbin-Watson:                   0.057\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               29.203\n",
       "Skew:                           0.314   Prob(JB):                     4.56e-07\n",
       "Kurtosis:                       4.393   Cond. No.                         13.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the optimal model using backward elimination\n",
    "import statsmodels.formula.api as sm\n",
    "# X = np.append(arr = np.ones((50, 1)).astype(float), values = X, axis = 1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   7.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 21 Feb 2018</td> <th>  Prob (F-statistic):</th> <td>1.38e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:11:07</td>     <th>  Log-Likelihood:    </th> <td> -724.33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>   1459.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   295</td>      <th>  BIC:               </th> <td>   1477.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.3995</td> <td>    0.083</td> <td>    4.821</td> <td> 0.000</td> <td>    0.236</td> <td>    0.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.2872</td> <td>    0.116</td> <td>    2.481</td> <td> 0.014</td> <td>    0.059</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>   -0.9915</td> <td>    0.403</td> <td>   -2.463</td> <td> 0.014</td> <td>   -1.784</td> <td>   -0.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.8561</td> <td>    0.646</td> <td>    1.325</td> <td> 0.186</td> <td>   -0.416</td> <td>    2.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>   -0.1708</td> <td>    1.134</td> <td>   -0.151</td> <td> 0.880</td> <td>   -2.402</td> <td>    2.061</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>26.205</td> <th>  Durbin-Watson:     </th> <td>   0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>   9.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.171</td> <th>  Prob(JB):          </th> <td> 0.00684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.175</td> <th>  Cond. No.          </th> <td>    13.7</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.112\n",
       "Model:                            OLS   Adj. R-squared:                  0.097\n",
       "Method:                 Least Squares   F-statistic:                     7.434\n",
       "Date:                Wed, 21 Feb 2018   Prob (F-statistic):           1.38e-06\n",
       "Time:                        17:11:07   Log-Likelihood:                -724.33\n",
       "No. Observations:                 300   AIC:                             1459.\n",
       "Df Residuals:                     295   BIC:                             1477.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.3995      0.083      4.821      0.000       0.236       0.563\n",
       "x2             0.2872      0.116      2.481      0.014       0.059       0.515\n",
       "x3            -0.9915      0.403     -2.463      0.014      -1.784      -0.199\n",
       "x4             0.8561      0.646      1.325      0.186      -0.416       2.128\n",
       "x5            -0.1708      1.134     -0.151      0.880      -2.402       2.061\n",
       "==============================================================================\n",
       "Omnibus:                       26.205   Durbin-Watson:                   0.042\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):                9.971\n",
       "Skew:                           0.171   Prob(JB):                      0.00684\n",
       "Kurtosis:                       2.175   Cond. No.                         13.7\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 1, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear models for regression\n",
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  0.   ,  0.   , ...,  0.663, -0.15 ,  0.042],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  0.647, -0.209,  0.057],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  0.663, -0.213,  0.068],\n",
       "       ..., \n",
       "       [ 0.   ,  0.   ,  0.   , ..., -0.385,  0.278,  0.052],\n",
       "       [ 0.   ,  0.   ,  0.   , ..., -0.385,  0.278,  0.053],\n",
       "       [ 0.   ,  0.   ,  0.   , ...,  0.389,  0.154, -0.155]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
